# üîç Deepfake Detection Tool

**AI-powered identity verification and deepfake detection for secure video authentication.**

---

## üìã Table of Contents

- [Overview](#overview)
- [Why This Tool Exists](#why-this-tool-exists)
- [How It Works](#how-it-works)
- [Repository Structure](#repository-structure)
- [Data Flow Process](#data-flow-process)
- [Installation](#installation)
- [Usage Guide](#usage-guide)
- [Understanding Results](#understanding-results)
- [Training Data](#training-data)
- [Configuration](#configuration)
- [Troubleshooting](#troubleshooting)

---

## Overview

The **Deepfake Detection Tool** is an AI-powered system that verifies whether a video is authentic or artificially generated (deepfake). It uses **Google Gemini 3** as its core AI engine combined with computer vision preprocessing to analyze multiple authenticity signals.

### Key Features

| Feature | Description |
|---------|-------------|
| **Identity Verification** | Compares video subject to a reference photo |
| **Book Cover Analysis** | Verifies held objects via OCR and internet search |
| **Biometric Analysis** | Analyzes eye blinks, micro-expressions, body movement |
| **AI-Powered Detection** | Gemini 3 multimodal analysis for comprehensive assessment |
| **Detailed Reporting** | JSON output with layer-by-layer breakdown |

---

## Why This Tool Exists

### The Business Problem

Companies often need to verify that a **real person** is performing an action themselves, not through manipulation or impersonation. Common scenarios include:

- **Remote Identity Verification**: Verifying that the person submitting documents is who they claim to be
- **Video KYC (Know Your Customer)**: Banks and financial services requiring video proof of identity
- **Remote Onboarding**: Companies verifying new employees or customers via video
- **High-Value Transactions**: Confirming the account holder personally authorizes actions
- **Legal Documentation**: Ensuring the signer is present and aware of the document

### The Solution

This tool provides a **multi-layer verification system** that:

1. **Confirms Identity**: The person in the video matches the provided reference photo
2. **Proves Awareness**: The subject holds a physical book (difficult to fake) and states their name/workplace
3. **Detects Manipulation**: Multiple analysis layers detect AI-generated or manipulated content
4. **Provides Confidence Scores**: Clear verdict with detailed reasoning for human review

### Why Hold a Book?

The book requirement serves as a **physical proof of presence**:
- Books are unique real-world objects that are hard to generate convincingly
- Text on covers provides OCR verification opportunities
- The book can be verified against online databases (Is it a real book?)
- Holding an object tests natural hand movements and interactions

---

## How It Works

### Input Requirements

| Input | Description | Format |
|-------|-------------|--------|
| **Reference Photo** | Clear photo of the person's face | JPEG, PNG, WebP (min 512√ó512px) |
| **Verification Video** | Video of person stating name/workplace while holding a book | MP4, WebM, MOV (max 60s) |

### Analysis Layers

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     DEEPFAKE DETECTION LAYERS                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ BOOK ANALYSIS   ‚îÇ  ‚îÇ EYE ANALYSIS    ‚îÇ  ‚îÇ EXPRESSION      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ OCR extraction‚îÇ  ‚îÇ ‚Ä¢ Blink rate    ‚îÇ  ‚îÇ ‚Ä¢ Micro-gestures‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Spelling check‚îÇ  ‚îÇ ‚Ä¢ Blink duration‚îÇ  ‚îÇ ‚Ä¢ Natural motion‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Book database ‚îÇ  ‚îÇ ‚Ä¢ Eye movement  ‚îÇ  ‚îÇ ‚Ä¢ Face symmetry ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                     ‚îÇ              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ BODY MOVEMENT   ‚îÇ  ‚îÇ IDENTITY MATCH  ‚îÇ  ‚îÇ GEMINI AI       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Head movement ‚îÇ  ‚îÇ ‚Ä¢ Face embedding‚îÇ  ‚îÇ ‚Ä¢ Multimodal    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Hand gestures ‚îÇ  ‚îÇ ‚Ä¢ Frame-to-frame‚îÇ  ‚îÇ ‚Ä¢ Comprehensive ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Natural pacing‚îÇ  ‚îÇ ‚Ä¢ Reference match‚îÇ ‚îÇ ‚Ä¢ Deep analysis ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                     ‚îÇ              ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                    ‚îÇ   WEIGHTED SCORING    ‚îÇ                       ‚îÇ
‚îÇ                    ‚îÇ   & FINAL VERDICT     ‚îÇ                       ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Repository Structure

```
deepfake-detection/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                 # This documentation
‚îú‚îÄ‚îÄ üìÑ PRD.md                    # Product Requirements Document
‚îú‚îÄ‚îÄ üìÑ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ üìÑ .env.example              # Environment variable template
‚îú‚îÄ‚îÄ üìÑ .gitignore                # Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                      # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Package exports
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ models.py                # Data models & types
‚îÇ   ‚îú‚îÄ‚îÄ detector.py              # Main detection orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # CLI entry point
‚îÇ   ‚îú‚îÄ‚îÄ cli_output.py            # CLI formatting utilities
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ preprocessing/        # Input processing modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video.py             # Video frame extraction (OpenCV)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ face.py              # Face detection (MediaPipe)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ audio.py             # Audio transcription (Whisper)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ analyzers/            # Detection analysis modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ book.py              # Book verification (OCR + APIs)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ book_api.py          # OpenLibrary/Google Books search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ biometric.py         # Biometric coordinator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eye.py               # Eye blink analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ movement.py          # Facial/body movement analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ identity.py          # Face matching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini.py            # Gemini API integration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py           # AI prompts
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ utils/                # Utility modules
‚îÇ       ‚îú‚îÄ‚îÄ helpers.py           # Helper functions
‚îÇ       ‚îî‚îÄ‚îÄ merge.py             # Result merging
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                    # Test files
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îî‚îÄ‚îÄ üìÅ training/                 # Training data (optional)
    ‚îú‚îÄ‚îÄ üìÅ real/                 # Known authentic videos
    ‚îÇ   ‚îú‚îÄ‚îÄ person1_real_01.mp4
    ‚îÇ   ‚îî‚îÄ‚îÄ person1_real_02.mp4
    ‚îî‚îÄ‚îÄ üìÅ fake/                 # Known deepfake videos
        ‚îú‚îÄ‚îÄ person1_fake_01.mp4
        ‚îî‚îÄ‚îÄ person1_fake_02.mp4
```

---

## Data Flow Process

### Step-by-Step Analysis Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          DATA FLOW PROCESS                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   INPUT                    PREPROCESSING                 ANALYSIS
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Reference   ‚îÇ          ‚îÇ                 ‚îÇ         ‚îÇ                 ‚îÇ
‚îÇ Photo       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Face Detection ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Face Embedding  ‚îÇ
‚îÇ (photo.jpg) ‚îÇ          ‚îÇ  + Embedding    ‚îÇ         ‚îÇ (128-dim vector)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                              ‚îÇ
                                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Video File  ‚îÇ          ‚îÇ                 ‚îÇ         ‚îÇ Frame-by-frame  ‚îÇ
‚îÇ (video.mp4) ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Frame Extraction‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Face Comparison ‚îÇ
‚îÇ             ‚îÇ          ‚îÇ (10 fps)        ‚îÇ         ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ                           ‚îÇ
                                  ‚ñº                           ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ Audio Extraction‚îÇ         ‚îÇ Book Detection  ‚îÇ
                         ‚îÇ + Transcription ‚îÇ         ‚îÇ + OCR           ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ                           ‚îÇ
                                  ‚ñº                           ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ Biometric       ‚îÇ         ‚îÇ Book Verification‚îÇ
                         ‚îÇ Analysis:       ‚îÇ         ‚îÇ ‚Ä¢ OpenLibrary   ‚îÇ
                         ‚îÇ ‚Ä¢ Eye blinks    ‚îÇ         ‚îÇ ‚Ä¢ Google Books  ‚îÇ
                         ‚îÇ ‚Ä¢ Expressions   ‚îÇ         ‚îÇ ‚Ä¢ Spelling check‚îÇ
                         ‚îÇ ‚Ä¢ Body movement ‚îÇ         ‚îÇ                 ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ                           ‚îÇ
                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                ‚îÇ
                                                ‚ñº
                                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                  ‚îÇ     GEMINI AI ANALYSIS   ‚îÇ
                                  ‚îÇ  ‚Ä¢ Multimodal reasoning  ‚îÇ
                                  ‚îÇ  ‚Ä¢ Cross-layer validation‚îÇ
                                  ‚îÇ  ‚Ä¢ Pattern detection     ‚îÇ
                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                               ‚îÇ
                                               ‚ñº
                                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                  ‚îÇ    RESULT AGGREGATION   ‚îÇ
                                  ‚îÇ  ‚Ä¢ Weighted scoring     ‚îÇ
                                  ‚îÇ  ‚Ä¢ Confidence calculation‚îÇ
                                  ‚îÇ  ‚Ä¢ Final verdict        ‚îÇ
                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                               ‚îÇ
                                               ‚ñº
   OUTPUT
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DETECTION REPORT                                                        ‚îÇ
‚îÇ ‚Ä¢ Verdict: LIKELY_DEEPFAKE / LIKELY_AUTHENTIC / INCONCLUSIVE           ‚îÇ
‚îÇ ‚Ä¢ Confidence Score: 0-100%                                              ‚îÇ
‚îÇ ‚Ä¢ Layer-by-layer findings                                               ‚îÇ
‚îÇ ‚Ä¢ Evidence frames                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Detailed Step Descriptions

| Step | Module | What It Does | Possible Results |
|------|--------|--------------|------------------|
| **1. Reference Processing** | `face.py` | Extracts face from reference photo, generates 128-dimensional face embedding | Face found/not found |
| **2. Frame Extraction** | `video.py` | Extracts video frames at 10 fps, gets metadata | Frames extracted, duration calculated |
| **3. Audio Extraction** | `audio.py` | Extracts audio track, transcribes to text | Speech transcription for lip-sync analysis |
| **4. Book Detection** | `book.py` | Detects book in frames, extracts text via OCR | Book title, author, text quality |
| **5. Book Verification** | `book_api.py` | Searches OpenLibrary/Google Books for the book | Book exists/not found, publisher info |
| **6. Spelling Analysis** | `book.py` | Checks OCR text for AI-generated artifacts | Spelling errors, garbled text |
| **7. Eye Analysis** | `eye.py` | Measures blink rate, duration, patterns | Normal/abnormal blink behavior |
| **8. Expression Analysis** | `movement.py` | Tracks facial micro-expressions over time | Natural/static/jerky expressions |
| **9. Body Movement** | `movement.py` | Analyzes head movement and body pacing | Natural/unnatural movements |
| **10. Identity Matching** | `identity.py` | Compares video faces to reference photo | Match percentage, consistency |
| **11. Gemini Analysis** | `gemini.py` | Comprehensive AI multimodal analysis | Detailed observations across all dimensions |
| **12. Score Aggregation** | `detector.py` | Combines all layer scores with weights | Weighted confidence score |
| **13. Verdict Determination** | `detector.py` | Converts score to verdict | LIKELY_DEEPFAKE / LIKELY_AUTHENTIC / INCONCLUSIVE |

---

## Installation

### Prerequisites

Before installing Python packages, ensure you have these system dependencies:

| Dependency | Purpose | Required |
|------------|---------|----------|
| **CMake** | Required to build `dlib` (face recognition) | ‚úÖ Yes |
| **Tesseract OCR** | Text extraction from book covers | ‚úÖ Yes |
| **FFmpeg** | Audio extraction from videos | ‚úÖ Yes |
| **Python 3.10+** | Runtime | ‚úÖ Yes |

### Step 1: Install System Dependencies

```bash
# macOS (using Homebrew)
brew install cmake tesseract ffmpeg

# Ubuntu/Debian
sudo apt install cmake tesseract-ocr ffmpeg

# Windows (using Chocolatey)
choco install cmake tesseract ffmpeg
```

> ‚ö†Ô∏è **Important:** CMake must be installed BEFORE running `pip install`. The `face-recognition` library requires CMake to compile its C++ dependencies.

### Step 2: Create Virtual Environment (Recommended)

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# or
venv\Scripts\activate     # Windows
```

### Step 3: Install Python Dependencies

```bash
pip install -r requirements.txt
```

### Step 3: Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your Gemini API key
# GEMINI_API_KEY=your_api_key_here
```

### Getting a Gemini API Key

1. Go to [Google AI Studio](https://aistudio.google.com/)
2. Sign in with your Google account
3. Click "Get API Key" ‚Üí "Create API Key"
4. Copy the key and paste into your `.env` file

---

## Usage Guide

### Basic Usage

The tool requires two inputs:
1. **Reference Photo** (`--photo` or `-p`): A clear photo of the person's face
2. **Video File** (`--video` or `-v`): The video to analyze

```bash
# Basic analysis
python -m src.main --photo reference.jpg --video verification.mp4

# Short form
python -m src.main -p reference.jpg -v verification.mp4
```

### Save Results to File

```bash
# Save JSON report
python -m src.main -p reference.jpg -v verification.mp4 --output result.json
```

### Analysis Modes

```bash
# Full analysis (default) - preprocessing + Gemini
python -m src.main -p photo.jpg -v video.mp4

# Gemini only (faster, less detailed)
python -m src.main -p photo.jpg -v video.mp4 --gemini-only

# Preprocessing only (no API calls to Gemini)
python -m src.main -p photo.jpg -v video.mp4 --no-gemini
```

### Provide API Key via Command Line

```bash
python -m src.main -p photo.jpg -v video.mp4 --api-key YOUR_API_KEY
```

### Programmatic Usage

```python
from src.detector import DeepfakeDetector

# Initialize detector
detector = DeepfakeDetector()

# Run analysis
result = detector.analyze(
    reference_photo="path/to/reference.jpg",
    video_path="path/to/video.mp4"
)

# Access results
print(f"Verdict: {result.verdict.value}")
print(f"Confidence: {result.confidence_score:.2%}")

# Get detailed layer results
if result.book_verification:
    print(f"Book Title: {result.book_verification.book_title}")
    print(f"Book Found: {result.book_verification.book_found}")

# Save to JSON
import json
with open("result.json", "w") as f:
    json.dump(result.to_dict(), f, indent=2)

# Clean up
detector.close()
```

---

## Understanding Results

### Verdicts Explained

| Verdict | Confidence Score | Meaning |
|---------|------------------|---------|
| **LIKELY_AUTHENTIC** | 0% - 50% | Video appears genuine, low manipulation indicators |
| **INCONCLUSIVE** | 50% - 70% | Unable to determine, requires human review |
| **LIKELY_DEEPFAKE** | 70% - 100% | Strong indicators of manipulation detected |

> **Note**: Score represents likelihood of deepfake. Lower = more likely authentic.

---

### Example 1: LIKELY_AUTHENTIC (Low Suspicion)

```
============================================================
ANALYSIS RESULTS
============================================================

VERDICT:             LIKELY_AUTHENTIC
Confidence Score:    23.00%
Processing Time:     42.3s

------------------------------------------------------------
LAYER SCORES
------------------------------------------------------------

Book Verification: 15.00%
  ‚Ä¢ Detected title: Thinking, Fast and Slow
  ‚Ä¢ Book found: 'Thinking, Fast and Slow' by Daniel Kahneman
  ‚Ä¢ Publisher verified: Farrar, Straus and Giroux

Eye Analysis: 25.00%
  ‚Ä¢ Normal blink rate: 17.2/min
  ‚Ä¢ Normal blink duration: 285ms

Facial Expressions: 20.00%
  ‚Ä¢ Natural facial movement patterns
  ‚Ä¢ Normal micro-expression variance

Body Movement: 30.00%
  ‚Ä¢ Natural head movement patterns
  ‚Ä¢ Normal body sway detected

Identity Match: 25.00%
  ‚Ä¢ High identity match: 92.00%
  ‚Ä¢ Consistent identity across frames

============================================================
```

**What This Means:**
- ‚úÖ The book is real and correctly spelled
- ‚úÖ Blink rate and duration are within normal range
- ‚úÖ Facial movements appear natural
- ‚úÖ The person matches the reference photo with 92% similarity
- ‚úÖ **Recommended Action**: Approve the verification

---

### Example 2: LIKELY_DEEPFAKE (High Suspicion)

```
============================================================
ANALYSIS RESULTS
============================================================

VERDICT:             LIKELY_DEEPFAKE
Confidence Score:    85.00%
Processing Time:     38.7s

------------------------------------------------------------
LAYER SCORES
------------------------------------------------------------

Book Verification: 80.00%
  ‚Ä¢ Detected title: Thinkng Fast adn Slow
  ‚Ä¢ Spelling issues: ['Thinkng', 'adn']
  ‚Ä¢ Book not found in online databases

Eye Analysis: 90.00%
  ‚Ä¢ Very low blink rate: 3.2/min (normal: 15-20)
  ‚Ä¢ Abnormal blink duration: 45ms

Facial Expressions: 85.00%
  ‚Ä¢ Very static facial movements detected
  ‚Ä¢ Inconsistent micro-expression patterns

Body Movement: 75.00%
  ‚Ä¢ Unusually still head position
  ‚Ä¢ Jerky head movements detected

Identity Match: 70.00%
  ‚Ä¢ Moderate identity match: 58.00%
  ‚Ä¢ High identity variance across frames: 0.0823

------------------------------------------------------------
EVIDENCE FRAMES
------------------------------------------------------------
  Frame 45 (00:01.87): Blink anomaly detected
  Frame 128 (00:05.33): Identity drift observed
  Frame 256 (00:10.67): Book text distortion

============================================================
```

**What This Means:**
- ‚ùå The book title has spelling errors (AI-generated text artifact)
- ‚ùå The person barely blinks (3.2/min vs normal 15-20/min)
- ‚ùå Facial movements are unnaturally static
- ‚ùå Identity varies significantly across frames
- ‚ùå **Recommended Action**: REJECT - Request in-person verification

---

### Example 3: INCONCLUSIVE (Requires Review)

```
============================================================
ANALYSIS RESULTS
============================================================

VERDICT:             INCONCLUSIVE
Confidence Score:    58.00%
Processing Time:     45.1s

------------------------------------------------------------
LAYER SCORES
------------------------------------------------------------

Book Verification: 45.00%
  ‚Ä¢ Detected title: The Art of War
  ‚Ä¢ Book found: 'The Art of War' by Sun Tzu
  ‚Ä¢ Gemini: Text partially obscured by hand

Eye Analysis: 65.00%
  ‚Ä¢ Low blink rate: 11.3/min (normal: 15-20)
  ‚Ä¢ Normal blink duration: 312ms

Facial Expressions: 55.00%
  ‚Ä¢ Moderate facial movement variance
  ‚Ä¢ Some micro-expression inconsistencies

Body Movement: 50.00%
  ‚Ä¢ Natural head movement patterns
  ‚Ä¢ Some unusual hand positioning

Identity Match: 60.00%
  ‚Ä¢ Moderate identity match: 71.00%
  ‚Ä¢ Moderate identity variance: 0.0312

============================================================
```

**What This Means:**
- ‚ö†Ô∏è Book is real but text is partially hidden
- ‚ö†Ô∏è Blink rate is slightly below normal range
- ‚ö†Ô∏è Some inconsistencies but not definitive
- ‚ö†Ô∏è Identity match is borderline (71%)
- ‚ö†Ô∏è **Recommended Action**: Request human review or additional verification

---

### Recommended Actions by Verdict

| Verdict | Action | Details |
|---------|--------|---------|
| **LIKELY_AUTHENTIC** | ‚úÖ Approve | Proceed with verification |
| **INCONCLUSIVE** | üëÅÔ∏è Human Review | Have a trained operator review the video |
| **LIKELY_DEEPFAKE** | ‚ùå Reject | Request in-person verification or additional proof |

---

## Training Data

### Purpose

Training data helps calibrate the system for your specific use case. While the tool works out-of-the-box, providing examples of real and fake videos improves accuracy.

### Directory Structure

Create a `training/` folder in your project root:

```
training/
‚îú‚îÄ‚îÄ real/                        # Known authentic videos
‚îÇ   ‚îú‚îÄ‚îÄ person1_real_01.mp4      # Real video of person 1
‚îÇ   ‚îú‚îÄ‚îÄ person1_real_02.mp4      # Another real video of person 1
‚îÇ   ‚îú‚îÄ‚îÄ person2_real_01.mp4      # Real video of person 2
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ fake/                        # Known deepfake videos
    ‚îú‚îÄ‚îÄ person1_fake_01.mp4      # Deepfake of person 1
    ‚îú‚îÄ‚îÄ person1_fake_02.mp4      # Another deepfake of person 1
    ‚îú‚îÄ‚îÄ person2_fake_01.mp4      # Deepfake of person 2
    ‚îî‚îÄ‚îÄ ...
```

### File Naming Convention

Use this naming pattern for training files:

```
{person_id}_{label}_{sequence}.{extension}
```

| Component | Values | Example |
|-----------|--------|---------|
| `person_id` | Unique identifier for the person | `person1`, `john_doe`, `user_12345` |
| `label` | `real` or `fake` | `real`, `fake` |
| `sequence` | Number for multiple videos | `01`, `02`, `03` |
| `extension` | Video format | `mp4`, `webm`, `mov` |

**Examples:**
- `john_doe_real_01.mp4` - Real video of John Doe
- `john_doe_fake_01.mp4` - Deepfake video of John Doe
- `user_12345_real_02.mp4` - Second real video of user 12345

### Reference Photos for Training

Place reference photos alongside training videos:

```
training/
‚îú‚îÄ‚îÄ references/                  # Reference photos
‚îÇ   ‚îú‚îÄ‚îÄ person1_reference.jpg
‚îÇ   ‚îú‚îÄ‚îÄ person2_reference.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ real/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ fake/
    ‚îî‚îÄ‚îÄ ...
```

### Running Training Evaluation

```bash
# Evaluate accuracy on training set (future feature)
python -m src.main --evaluate training/
```

---

## Configuration

### Environment Variables

Edit `.env` file:

```bash
# Required
GEMINI_API_KEY=your_gemini_api_key_here

# Optional: Higher rate limits for book search
GOOGLE_BOOKS_API_KEY=your_google_books_api_key

# Detection thresholds (optional)
DEEPFAKE_THRESHOLD=0.5          # Below this = LIKELY_AUTHENTIC
AUTHENTIC_THRESHOLD=0.7          # Above this = LIKELY_DEEPFAKE

# Processing settings (optional)
MAX_VIDEO_DURATION=60            # Maximum video length in seconds
FRAME_EXTRACTION_FPS=10          # Frames per second to extract
```

### Threshold Tuning

Adjust thresholds based on your security requirements:

| Use Case | DEEPFAKE_THRESHOLD | AUTHENTIC_THRESHOLD |
|----------|-------------------|---------------------|
| **High Security** (banking) | 0.4 | 0.6 |
| **Standard** (default) | 0.5 | 0.7 |
| **Lenient** (low-risk) | 0.6 | 0.8 |

---

## Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| `GEMINI_API_KEY is required` | Set API key in `.env` or use `--api-key` |
| `Cannot open video` | Check video format (MP4, WebM, MOV supported) |
| `No face detected in reference` | Use a clearer, front-facing photo |
| `OCR error` | Install Tesseract: `brew install tesseract` |
| `Audio extraction failed` | Install FFmpeg: `brew install ffmpeg` |

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | LIKELY_AUTHENTIC - Verification passed |
| 1 | INCONCLUSIVE - Requires human review |
| 2 | LIKELY_DEEPFAKE - Verification failed |

---

## License

MIT License - See LICENSE file for details.

---

## Support

For issues, feature requests, or questions:
- Open an issue on GitHub
- Review the PRD.md for detailed technical specifications
